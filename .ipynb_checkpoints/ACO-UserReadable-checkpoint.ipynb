{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3d430d",
   "metadata": {},
   "source": [
    "# Ant Colony Optimization\n",
    "\n",
    "### Ant class: the “agents” that will be traversing the graph.\n",
    "\n",
    "\n",
    "### Ant colony: a colony of ants. It is responsible for moving ants to their starting node as well as prompting the ants to move to the next node on their “journey”.\n",
    "\n",
    "\n",
    "### Ant graph: the graph our agents will be traversing over\n",
    "\n",
    "\n",
    "### Task: the task the ants will complete (\"watch\" movies and rate them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae87c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9147f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets think about our cost function for a bit\n",
    "# we want to use the users ratings to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb61d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ant: \n",
    "    trail = []\n",
    "    visited_jobs = []\n",
    "    review_list = []\n",
    "    current_film = 0;\n",
    "    \n",
    "    def __init__(self, review_list):\n",
    "        self.review_list = sorted(self.review_list, key=lambda x: x[1])\n",
    "    \n",
    "    def trail_len(self):\n",
    "        return len(self.trail)\n",
    "    \n",
    "    def get_trail(self):\n",
    "        return self.trail\n",
    "    \n",
    "    def get_current(self):\n",
    "        return self.current_film\n",
    "    \n",
    "    def has_visited (self,i):\n",
    "        self.visited_jobs[i]\n",
    "        \n",
    "    def watch_movie (self,movieID):\n",
    "        self.current_film = movieID\n",
    "        self.trail.append(movieID)\n",
    "        \n",
    "    def clear (self):\n",
    "        self.trail = []\n",
    "        self.visited_jobs = []\n",
    "        self.current_film = 0;\n",
    "        \n",
    "        \n",
    "    #get user review for specific movie returns a neutral rating of 2.5 if it does not exist\n",
    "    def get_task_cost(self,movieID):\n",
    "        cost = [y for x, y in self.review_list if x == movieID ]\n",
    "        return  2.5 if cost == [] else cost[0]    \n",
    "    def get_best_film(self):\n",
    "        return self.review_list.pop(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8950c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntColony:\n",
    "    \n",
    "    ants = []\n",
    "    alpha = 0\n",
    "    beta = 0 \n",
    "    \n",
    "    def __init__(self,antID_list,filename,alpha =0.5,beta = 0.4 ):\n",
    "        user_reviews =  pd.read_csv(filename)\n",
    "        self.ants = []\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "        for ID in antID_list:\n",
    "            rev = ast.literal_eval(user_reviews.loc[user_reviews['userId'] == ID][\"ratings_list\"].tolist()[0])\n",
    "            new_ant = Ant(rev)\n",
    "#             new_ant.watch_movie(new_ant.get_best_film()[0])\n",
    "            self.ants.append(new_ant)\n",
    "    \n",
    "        \n",
    "        \n",
    "    def prob_fx (self,rating, current_weight,sum_weights):\n",
    "        prob = ((current_weight ** self.alpha) * (rating ** self.beta)) / sum_weights\n",
    "        return prob\n",
    "            \n",
    "        \n",
    "    def move_all_ants (self,edge_weights):\n",
    "#         print(\"moving all ants\")\n",
    "#         print(f\"num ants: {len(self.ants)}\")\n",
    "        for ant in self.ants:\n",
    "            movie_id = self.determine_next_movie(ant,edge_weights[ant.get_current ()])\n",
    "            ant.watch_movie(movie_id)\n",
    "\n",
    "    def prep_for_test (self): \n",
    "        self.alpha = 0.9 \n",
    "        self.beta = 0.1\n",
    "        \n",
    "    def return_all_tours(self):\n",
    "        t = []\n",
    "        #print(f\"Num ants : {len(self.ants)}\")\n",
    "        for ant in self.ants:\n",
    "            #print(len(ant.get_trail()))\n",
    "            if (len(ant.get_trail()) > 20):\n",
    "                print(ant.get_trail())\n",
    "            \n",
    "            t.append(ant.get_trail())\n",
    "        \n",
    "        ## will be used for global pheremone updating \n",
    "        \n",
    "        #print(len(t))\n",
    "        return t\n",
    "    \n",
    "    #here we use the index of the ant rather than its ID \n",
    "    def get_ant_rating (self,antIndex,movieID):\n",
    "        return self.ants[antIndex].get_task_cost(movieID)\n",
    "    \n",
    "    def clear (self):\n",
    "        for ant in self.ants:\n",
    "            ant.clear()\n",
    "        \n",
    "            \n",
    "    def determine_next_movie(self,ant,edge_weights):\n",
    "        current_movie = ant.get_current ()\n",
    "        trail = ant.get_trail()\n",
    "        temp_weights = {}\n",
    "        probs = {}\n",
    "        sum_cost = 0 \n",
    "        \n",
    "        #removes all nodes we have already visited\n",
    "        for ew in edge_weights.keys():\n",
    "            if (ew not in trail):\n",
    "                temp_weights [ew] = edge_weights[ew]\n",
    "                \n",
    "        # getting sum cost\n",
    "        for vertex in temp_weights.keys():\n",
    "            if (vertex not in ant.get_trail()):\n",
    "                rating = ant.get_task_cost(vertex)\n",
    "                weight = temp_weights[vertex]\n",
    "                sum_cost += ((weight ** self.alpha) * (rating ** self.beta))\n",
    "            \n",
    "        for vertex in temp_weights.keys():\n",
    "            if (vertex not in ant.get_trail()):\n",
    "                rating = ant.get_task_cost(vertex)\n",
    "                weight = temp_weights[vertex]\n",
    "                probs[vertex] = self.prob_fx(rating,weight,sum_cost)\n",
    "            \n",
    "            \n",
    "#         print(f\"Probs : {probs.keys()}\")\n",
    "        #Chooses the next film based on probabilities \n",
    "        #print (random.choices(list(probs.keys()), weights= list(probs.values()), k=1)[0])\n",
    "        try:\n",
    "            choice = random.choices(list(probs.keys()), weights= list(probs.values()), k=1)\n",
    "        except:\n",
    "            choice = []\n",
    "        return 0 if choice == [] else choice[0]\n",
    "    \n",
    "\n",
    "            \n",
    "                \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6508bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    title = \"\"\n",
    "    genres = \"\"\n",
    "    mID = None\n",
    "    \n",
    "    def __init__(self, movie,movie_details):\n",
    "        self.mId = movie\n",
    "        self.title = movie_details[\"title\"].to_string(index= False)\n",
    "        self.genres = movie_details[\"genres\"].to_string().split(\" \")[-1]\n",
    "    \n",
    "    def print_Task(self):\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(f\"Title: {self.title}\")\n",
    "        print(f\"genres: {self.genres}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080ebc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ant_Graph:\n",
    "    \n",
    "    graph_edge_weights = {}\n",
    "    verticies   = None\n",
    "    trail_max_len = 0\n",
    "    num_ants = 0 \n",
    "    decay = 0 \n",
    "    ants = None\n",
    "    best_recommendations = []\n",
    "    \n",
    "    def __init__(self, movie_list,task_list, num_ants,num_movies_wanted,antID_list, filename = \"./generation_saves/ratings_gen_50.csv\", alpha =0.6, beta= 0.4, decay = 0.05):\n",
    "        self.num_ants = num_ants\n",
    "        self.trail_max_len = num_movies_wanted\n",
    "        self.vertices = task_list\n",
    "        self.decay = decay\n",
    "        self.graph_edge_weights = {}\n",
    "        \n",
    "        for movieID in movie_list:\n",
    "            if (movieID not in self.graph_edge_weights.keys()):\n",
    "                self.graph_edge_weights[movieID] = {}\n",
    "            for m in movie_list:\n",
    "                if (m != movieID):\n",
    "                    self.graph_edge_weights[movieID][m] = 0.5\n",
    "        \n",
    "        #creating a start node that does not belong to a movie, all agents will start there\n",
    "        self.graph_edge_weights[0] = {}\n",
    "        for movieID in movie_list:\n",
    "            self.graph_edge_weights[0][movieID] = 0.5\n",
    "            \n",
    "        self.ants = AntColony(antID_list,filename,alpha,beta)\n",
    "            \n",
    "    def clear(self): \n",
    "        self.graph_edge_weights = {}\n",
    "        self.verticies   = None\n",
    "        self.trail_max_len = 0\n",
    "        self.num_ants = 0 \n",
    "        self.decay = 0 \n",
    "        self.ants.clear()\n",
    "        self.ants = None\n",
    "        self.best_recommendations = []\n",
    "                    \n",
    "                    \n",
    "    def update_edge_weights (self):\n",
    "        \n",
    "        # we will chqnge the pheremones based on how much the user enjoyed that set (\"trail\") of movies\n",
    "        # it will be calculated as   cumulative_trail_Raitings/ total_possible ratings, bound between 0 and 1 \n",
    "        cumulative_ratings =  {}\n",
    "        tours = self.ants.return_all_tours()\n",
    "        for i,tour in enumerate(tours):\n",
    "            prev = 0 \n",
    "            for movie in tour:\n",
    "#                 print(len(tour))\n",
    "                curr = movie\n",
    "                rating = self.ants.get_ant_rating(i,movie)\n",
    "                if (prev not in list(cumulative_ratings.keys()) ):\n",
    "                     cumulative_ratings[prev] = {}\n",
    "                if (curr not in list(cumulative_ratings [prev].keys())):\n",
    "                    cumulative_ratings [prev][curr] = rating\n",
    "                else:\n",
    "                    cumulative_ratings [prev][curr] += rating\n",
    "                \n",
    "                prev = curr\n",
    "            \n",
    "        for startnode in cumulative_ratings.keys():\n",
    "            for nextnode in cumulative_ratings[startnode].keys():\n",
    "                self.graph_edge_weights[startnode][nextnode] *= (1- self.decay)\n",
    "                self.graph_edge_weights[startnode][nextnode] += (cumulative_ratings[startnode][nextnode] / (5* self.trail_max_len))\n",
    "                \n",
    "        del cumulative_ratings\n",
    "    \n",
    "\n",
    "    def compute_best_rec (self,exclude_list):\n",
    "        temp_list = []\n",
    "        self.ants.prep_for_test()\n",
    "        while (len(temp_list)< self.trail_max_len):\n",
    "            test_ant = Ant([])\n",
    "            nextid = self.ants.determine_next_movie(test_ant,self.graph_edge_weights [test_ant.get_current()])\n",
    "            test_ant.watch_movie(nextid)\n",
    "            if (nextid not in exclude_list):\n",
    "                temp_list.append(nextid)\n",
    "        \n",
    "        return temp_list\n",
    "    \n",
    "    def best_recomendations (self):\n",
    "        return self.best_recommendations\n",
    "    \n",
    "    def one_iter (self): \n",
    "#         print(\"running one iteration: \\n -------------------------------\")\n",
    "        #print(f\" trail max len : {self.trail_max_len}\")\n",
    "        self.ants.clear()\n",
    "        for step in range(0,self.trail_max_len):\n",
    "            #print(\"test\")\n",
    "            self.ants.move_all_ants(self.graph_edge_weights)\n",
    "            \n",
    "        self.update_edge_weights()\n",
    "        self.ants.clear()\n",
    "        \n",
    "            \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a3c0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "file = open(\"genresList.pkl\",'rb')\n",
    "genres = load(file)\n",
    "file.close()\n",
    "\n",
    "def create_genre_tracker ():\n",
    "    gt = {}\n",
    "    for g in genres:\n",
    "        gt[g] = 0 \n",
    "    return gt\n",
    "\n",
    "\n",
    "sim_df =  pd.read_csv(\"./simillarity_matrix.csv\")\n",
    "all_vals = []\n",
    "\n",
    "for index, row in sim_df.iterrows():\n",
    "    sim_list = ast.literal_eval(row[\"simillarity_vector\"])\n",
    "    all_vals += sim_list\n",
    "\n",
    "max_sim = max(all_vals)\n",
    "min_Sim = min(all_vals)\n",
    "\n",
    "def z_normalization (val):\n",
    "    return (val-min_Sim)/(max_sim - min_Sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8580bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_simillarity_ratings (l1,l2,movies):\n",
    "    l1_dict = dict(l1)\n",
    "    l2_dict = dict(l2)\n",
    "    simillarity = 0 \n",
    "    \n",
    "    genre_tracker1 = create_genre_tracker ()\n",
    "    genre_tracker2 = create_genre_tracker ()\n",
    "    \n",
    "    l2_keys = list(l2_dict.keys())\n",
    "    for key in l1_dict.keys():\n",
    "        m1_genres = movies.loc[movies['movieId'] == key  ,'genres'].values[0].split(\"|\")\n",
    "        for mg in m1_genres:\n",
    "            genre_tracker1 [mg] +=1\n",
    "        if key in l2_keys:\n",
    "            r1 = l1_dict [key]\n",
    "            r2 = l2_dict [key]\n",
    "            if (r1 < r2):\n",
    "                simillarity += 100*(r1/r2)\n",
    "            else:\n",
    "                simillarity+= 100*(r2/r1) \n",
    "                \n",
    "    for key in l2_keys:\n",
    "        try: \n",
    "            m2_genres = movies.loc[movies['movieId'] == key  ,'genres'].values[0].split(\"|\")\n",
    "            for mg in m2_genres:\n",
    "                genre_tracker2 [mg] +=1\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    genre_simillarity =  0 \n",
    "    for g in genres:\n",
    "        tempg1 = genre_tracker1 [g]\n",
    "        tempg2 = genre_tracker2 [g]\n",
    "        if (tempg1 > 0 or tempg2 >0):\n",
    "            genre_simillarity += (1000* (min(tempg1,tempg2)/max(tempg1,tempg2))* min (tempg1,tempg2))\n",
    "        \n",
    "    return z_normalization(genre_simillarity + simillarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4586604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_simillarity_vector (ratings_df, userlist,movies,exclude_users):\n",
    "    simillarity_dict = {}\n",
    "    \n",
    "    for index, row in ratings_df.iterrows():\n",
    "        user2list = ast.literal_eval (row[\"ratings_list\"])\n",
    "        simillarity_dict [row[\"userId\"]] = compute_simillarity_ratings (userlist,user2list,movies)\n",
    "        \n",
    "    for u in exclude_users:\n",
    "        if (u in simillarity_dict.keys()):\n",
    "            del simillarity_dict[u]\n",
    "        \n",
    "    return [(k,v) for k ,v in simillarity_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a097b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_similar_users(num_agents,user_ratings,exclude_users, userlist,movies, randomize = False):\n",
    "    if ( not randomize):\n",
    "        sim_vec = compute_simillarity_vector (user_ratings, userlist,movies,exclude_users) \n",
    "    \n",
    "            \n",
    "        sim_vec.sort(key=lambda pair: pair[1])\n",
    "        return [a[0] for a in sim_vec[-num_agents:]]\n",
    "    else: \n",
    "        userids = list (range(1,len(user_ratings.index)))\n",
    "        return random.sample(userids, num_agents);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be8e7640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_printrecs (num_agents, num_iter, num_movies,exclude_users =[], userlist = [],rating_fn = \"./generation_saves/ratings_gen_50.csv\", simillarility_fn = \"./simillarity_matrix_normalized.csv\", alpha= 0.7,beta =0.3,decay=0.05):\n",
    "    # import datasets\n",
    "    print (\"importing datasets....\")\n",
    "    sim_df  = pd.read_csv(simillarility_fn)\n",
    "    movies  = pd.read_csv(f\"./ml-latest-small/movies.csv\")\n",
    "    user_ratings = pd.read_csv(rating_fn)\n",
    "    \n",
    "    ## if userlist is empty pick 50 random users as agents\n",
    "    rand = (len(userlist) == 0)\n",
    "        \n",
    "    ## if not empty userlist will be the most simillar users \n",
    "    print(f\"selecting {num_agents} simillar users...\")\n",
    "    users = select_similar_users(num_agents, user_ratings,exclude_users, userlist,movies, randomize = rand)\n",
    "    \n",
    "    ## determining all the movies that these users watched\n",
    "    print(\"configuring movie formatting...\")\n",
    "    movie_list = []\n",
    "    tasks = []\n",
    "    for uID in users:\n",
    "        film_list = ast.literal_eval(user_ratings.loc[user_ratings['userId'] == uID][\"ratings_list\"].tolist()[0])\n",
    "        for film,rating in film_list:\n",
    "            if (film not in movie_list):\n",
    "                movie_list.append(film)\n",
    "                tasks.append(Task(film,movies.loc[movies['movieId'] == film]))\n",
    "    \n",
    "    ## define the graph\n",
    "    print(\"creating the Graph...\")\n",
    "    graph = Ant_Graph(movie_list,tasks, num_agents ,num_movies, users, filename = rating_fn , alpha=alpha , beta= beta, decay = decay)\n",
    "    print(f\"Staring training fo {num_iter} iterations...\")\n",
    "    for i in tqdm(range (0,num_iter)):\n",
    "        graph.one_iter()\n",
    "        \n",
    "    movies_user_already_watched = [mid for mid,rate in userlist ]\n",
    "    recs = graph.compute_best_rec (movies_user_already_watched)\n",
    "    \n",
    "    print (\"based on your movie list [\" + \", \".join([movies.loc[movies['movieId'] == film][\"title\"].to_string(index= False) for film in movie_list[-10:]  ]) + \"] \\n You might like the following films\")\n",
    "    for task in tasks:\n",
    "        if (task.mId in recs):\n",
    "            task.print_Task()\n",
    "    \n",
    "    \n",
    "    ## Adding some cleanup code to clear all vars because for some reason every second call to main was failing \n",
    "    graph.clear()\n",
    "    del graph, movie_list, tasks, rand, users, user_ratings,sim_df,movies\n",
    "    gc.collect()\n",
    "    \n",
    "    return recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db822e7",
   "metadata": {},
   "source": [
    "## Training and testing \n",
    "\n",
    "### training \n",
    "\n",
    "Training is rather trivial, all weneed to do is make an appropriate call to main()\n",
    "\n",
    "### testing\n",
    "\n",
    "Testing is a bit more difficult. We do not have a list of people who have volunteered to test the system by watching the recomendations and rating them so we have to get creative. We can set a few users in our existing dataset as \"test users\" then we will take the first k ratings of the user as input/\"user history\" and the n-k as \"test ratings\" . We will determine how good the recomendations are using the percentage of the reccomendations that appear in the \"test ratings list and by comparing the ratings for movies that are in both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dad2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metric\n",
    "def evaluate_reccomendations (recs, test_set):\n",
    "    missing_recs =0 \n",
    "    ratings = []\n",
    "    for movieID in recs: \n",
    "        rating = next((y for x, y in test_set if x == movieID ), None)\n",
    "        if (rating == None):\n",
    "            missing_recs+=1\n",
    "        else: \n",
    "            ratings.append(rating)\n",
    "            \n",
    "    percent_overlap = (len(recs) - missing_recs) / len(recs)\n",
    "    \n",
    "    rating_accuracy = 0.5\n",
    "    if (len(ratings) > 0):\n",
    "        rating_accuracy = sum(ratings) / (5*len(ratings))\n",
    "    \n",
    "    return percent_overlap, rating_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd2c34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get 50 test users \n",
    "user_ratings = pd.read_csv(\"./ratings_organized.csv\")\n",
    "chosen_users = random.sample (list(range (0, len(user_ratings.index))),50)  ## we will pass this to main to make sure our train data does not include it \n",
    "\n",
    "train_revs, test_revs = [], []\n",
    "for i in chosen_users:\n",
    "    user_rev  = ast.literal_eval(user_ratings.iloc[[i]] [\"ratings_list\"].tolist()[0])\n",
    "    split_index = int (len(user_rev) * 0.5)\n",
    "    train_revs.append(user_rev[:split_index])\n",
    "    test_revs.append(user_rev[split_index:])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb7831",
   "metadata": {},
   "source": [
    "# Testing output now \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcd8a041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 50 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:15<00:00,  3.23it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:41\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recs \u001b[38;5;241m=\u001b[39m \u001b[43mmain_printrecs\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_agents\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_movies\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mexclude_users\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchosen_users\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserlist\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_revs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mrating_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./generation_saves/ratings_gen_50.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimillarility_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./simillarity_matrix_normalized.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mmain_printrecs\u001b[1;34m(num_agents, num_iter, num_movies, exclude_users, userlist, rating_fn, simillarility_fn, alpha, beta, decay)\u001b[0m\n\u001b[0;32m     33\u001b[0m movies_user_already_watched \u001b[38;5;241m=\u001b[39m [mid \u001b[38;5;28;01mfor\u001b[39;00m mid,rate \u001b[38;5;129;01min\u001b[39;00m userlist ]\n\u001b[0;32m     34\u001b[0m recs \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mcompute_best_rec (movies_user_already_watched)\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbased on your movie list [\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([movies\u001b[38;5;241m.\u001b[39mloc[movies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m film]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_string(index\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m film \u001b[38;5;129;01min\u001b[39;00m movie_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m:]  ]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m] \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You might like the following films\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (task\u001b[38;5;241m.\u001b[39mmId \u001b[38;5;129;01min\u001b[39;00m recs):\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     33\u001b[0m movies_user_already_watched \u001b[38;5;241m=\u001b[39m [mid \u001b[38;5;28;01mfor\u001b[39;00m mid,rate \u001b[38;5;129;01min\u001b[39;00m userlist ]\n\u001b[0;32m     34\u001b[0m recs \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mcompute_best_rec (movies_user_already_watched)\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbased on your movie list [\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[43mmovies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmovies\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovieId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilm\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_string(index\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m film \u001b[38;5;129;01min\u001b[39;00m movie_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m:]  ]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m] \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You might like the following films\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (task\u001b[38;5;241m.\u001b[39mmId \u001b[38;5;129;01min\u001b[39;00m recs):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1202\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;66;03m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:3864\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3862\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[0;32m   3863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3864\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3866\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   3867\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "recs = main_printrecs (num_agents =30 , num_iter = 50, num_movies = 5 ,exclude_users = chosen_users , userlist = train_revs[0] ,rating_fn = \"./generation_saves/ratings_gen_50.csv\", simillarility_fn = \"./simillarity_matrix_normalized.csv\", alpha= 0.7,beta =0.3,decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623966f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,rev_list in enumerate(train_revs):\n",
    "    print(f\"running training and testing for user {i}\\n --------------------------------------------\")\n",
    "    recs = main_printrecs (num_agents =30 , num_iter = 30, num_movies = 5 ,exclude_users = chosen_users , userlist = rev_list ,rating_fn = \"./generation_saves/ratings_gen_50.csv\", simillarility_fn = \"./simillarity_matrix_normalized.csv\", alpha= 0.7,beta =0.3,decay=0.05)\n",
    "    precent_overlap, ra = evaluate_reccomendations(recs,test_revs[i])\n",
    "    if (precent_overlap != 0 ):\n",
    "        ra_list.append(ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f1b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c7756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053e56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56704156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e353410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e085c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b7dce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
