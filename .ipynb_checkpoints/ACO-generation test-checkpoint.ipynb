{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3d430d",
   "metadata": {},
   "source": [
    "# Ant Colony Optimization\n",
    "\n",
    "### Ant class: the “agents” that will be traversing the graph.\n",
    "\n",
    "\n",
    "### Ant colony: a colony of ants. It is responsible for moving ants to their starting node as well as prompting the ants to move to the next node on their “journey”.\n",
    "\n",
    "\n",
    "### Ant graph: the graph our agents will be traversing over\n",
    "\n",
    "\n",
    "### Task: the task the ants will complete (\"watch\" movies and rate them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae87c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9147f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets think about our cost function for a bit\n",
    "# we want to use the users ratings to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb61d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ant: \n",
    "    \n",
    "    def __init__(self, review_list):\n",
    "        self.trail = []\n",
    "        self.visited_jobs = []\n",
    "        self.review_list = []\n",
    "        self.current_film = 0;\n",
    "        self.review_list = sorted(self.review_list, key=lambda x: x[1])\n",
    "    \n",
    "    def trail_len(self):\n",
    "        return len(self.trail)\n",
    "    \n",
    "    def get_trail(self):\n",
    "        return self.trail\n",
    "    \n",
    "    def get_current(self):\n",
    "        return self.current_film\n",
    "    \n",
    "    def has_visited (self,i):\n",
    "        self.visited_jobs[i]\n",
    "        \n",
    "    def watch_movie (self,movieID):\n",
    "        self.current_film = movieID\n",
    "        self.trail.append(movieID)\n",
    "        \n",
    "    def clear (self):\n",
    "        del self.trail[:]\n",
    "        self.visited_jobs = []\n",
    "        self.current_film = 0;\n",
    "        \n",
    "        \n",
    "    #get user review for specific movie returns a neutral rating of 2.5 if it does not exist\n",
    "    def get_task_cost(self,movieID):\n",
    "        cost = [y for x, y in self.review_list if x == movieID ]\n",
    "        return  2.5 if cost == [] else cost[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8950c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntColony:\n",
    "    \n",
    "    \n",
    "    def __init__(self,antID_list,filename,alpha =0.5,beta = 0.4 ):\n",
    "        user_reviews =  pd.read_csv(filename)\n",
    "        self.ants = []\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "        for ID in antID_list:\n",
    "            rev = ast.literal_eval(user_reviews.loc[user_reviews['userId'] == ID][\"ratings_list\"].tolist()[0])\n",
    "            new_ant = Ant(rev)\n",
    "            self.ants.append(new_ant)\n",
    "    \n",
    "        \n",
    "        \n",
    "    def prob_fx (self,rating, current_weight,sum_weights):\n",
    "        prob = ((current_weight ** self.alpha) * (rating ** self.beta)) / sum_weights\n",
    "        return prob\n",
    "            \n",
    "        \n",
    "    def move_all_ants (self,edge_weights):\n",
    "#         print(\"moving all ants\")\n",
    "#         print(f\"num ants: {len(self.ants)}\")\n",
    "        for ant in self.ants:\n",
    "            movie_id = self.determine_next_movie(ant,edge_weights[ant.get_current ()])\n",
    "            ant.watch_movie(movie_id)\n",
    "\n",
    "    def prep_for_test (self): \n",
    "        self.alpha = 0.9 \n",
    "        self.beta = 0.1\n",
    "        \n",
    "    def return_all_tours(self):\n",
    "        t = []\n",
    "        #print(f\"Num ants : {len(self.ants)}\")\n",
    "        for ant in self.ants:\n",
    "            #print(len(ant.get_trail()))\n",
    "            if (len(ant.get_trail()) > 20):\n",
    "                print(ant.get_trail())\n",
    "            \n",
    "            t.append(ant.get_trail())\n",
    "        \n",
    "        ## will be used for global pheremone updating \n",
    "        \n",
    "        #print(len(t))\n",
    "        return t\n",
    "    \n",
    "    #here we use the index of the ant rather than its ID \n",
    "    def get_ant_rating (self,antIndex,movieID):\n",
    "        return self.ants[antIndex].get_task_cost(movieID)\n",
    "    \n",
    "    def clear (self):\n",
    "        for ant in self.ants:\n",
    "            ant.clear()\n",
    "        \n",
    "            \n",
    "    def determine_next_movie(self,ant,edge_weights):\n",
    "        current_movie = ant.get_current ()\n",
    "        trail = ant.trail\n",
    "        temp_weights = {}\n",
    "        probs = {}\n",
    "        sum_cost = 0 \n",
    "        \n",
    "        #removes all nodes we have already visited\n",
    "        for ew in edge_weights.keys():\n",
    "            if (ew not in ant.trail):\n",
    "                temp_weights [ew] = edge_weights[ew]\n",
    "\n",
    "        # getting sum cost\n",
    "        for vertex in temp_weights.keys():\n",
    "            if (vertex not in ant.get_trail()):\n",
    "                rating = ant.get_task_cost(vertex)\n",
    "                weight = temp_weights[vertex]\n",
    "                sum_cost += ((weight ** self.alpha) * (rating ** self.beta))\n",
    "            \n",
    "        for vertex in temp_weights.keys():\n",
    "            if (vertex not in ant.get_trail() and vertex != 0 ):\n",
    "                rating = ant.get_task_cost(vertex)\n",
    "                weight = temp_weights[vertex]\n",
    "                probs[vertex] = self.prob_fx(rating,weight,sum_cost)\n",
    "            \n",
    "            \n",
    "#         print(f\"Probs : {probs.keys()}\")\n",
    "        #Chooses the next film based on probabilities \n",
    "        #print (random.choices(list(probs.keys()), weights= list(probs.values()), k=1)[0])\n",
    "        try:\n",
    "            choice = random.choices(list(probs.keys()), weights= list(probs.values()), k=1)\n",
    "        except:\n",
    "            temp = [k for k in edge_weights.keys()] \n",
    "            choice = random.choice(temp)\n",
    "        return 0 if choice == [] else choice[0]\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6508bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    title = \"\"\n",
    "    genres = \"\"\n",
    "    mID = None\n",
    "    \n",
    "    def __init__(self, movie,movie_details):\n",
    "        self.mId = movie\n",
    "        self.title = movie_details[\"title\"]\n",
    "        self.genres = movie_details[\"genres\"]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080ebc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ant_Graph:\n",
    "    \n",
    "    best_recommendations = []\n",
    "    \n",
    "    def __init__(self, movie_list,task_list, num_ants,num_movies_wanted,antID_list, filename = \"./generation_saves/ratings_gen_50.csv\", alpha =0.6, beta= 0.4, decay = 0.05):\n",
    "        self.num_ants = num_ants\n",
    "        self.trail_max_len = num_movies_wanted\n",
    "        self.vertices = task_list\n",
    "        self.decay = decay\n",
    "        self.graph_edge_weights = {}\n",
    "        \n",
    "        for movieID in movie_list:\n",
    "            if (movieID not in self.graph_edge_weights.keys()):\n",
    "                self.graph_edge_weights[movieID] = {}\n",
    "            for m in movie_list:\n",
    "                if (m != movieID):\n",
    "                    self.graph_edge_weights[movieID][m] = 0.5\n",
    "        \n",
    "        #creating a start node that does not belong to a movie, all agents will start there\n",
    "        self.graph_edge_weights[0] = {}\n",
    "        for movieID in movie_list:\n",
    "            if (movieID != 0):\n",
    "                self.graph_edge_weights[0][movieID] = 0.5\n",
    "            \n",
    "        self.ants = AntColony(antID_list,filename,alpha,beta)\n",
    "            \n",
    "    def clear(self): \n",
    "        self.graph_edge_weights = {}\n",
    "        self.verticies   = None\n",
    "        self.trail_max_len = 0\n",
    "        self.num_ants = 0 \n",
    "        self.decay = 0 \n",
    "        self.ants.clear()\n",
    "        self.ants = None\n",
    "        self.best_recommendations = []\n",
    "                    \n",
    "                    \n",
    "    def update_edge_weights (self):\n",
    "        \n",
    "        # we will chqnge the pheremones based on how much the user enjoyed that set (\"trail\") of movies\n",
    "        # it will be calculated as   cumulative_trail_Raitings/ total_possible ratings, bound between 0 and 1 \n",
    "        cumulative_ratings =  {}\n",
    "        tours = self.ants.return_all_tours()\n",
    "        for i,tour in enumerate(tours):\n",
    "            prev = 0 \n",
    "            for movie in tour:\n",
    "#                 print(len(tour))\n",
    "                curr = movie\n",
    "                rating = self.ants.get_ant_rating(i,movie)\n",
    "                if (prev not in list(cumulative_ratings.keys()) ):\n",
    "                     cumulative_ratings[prev] = {}\n",
    "                if (curr not in list(cumulative_ratings [prev].keys())):\n",
    "                    cumulative_ratings [prev][curr] = rating\n",
    "                else:\n",
    "                    cumulative_ratings [prev][curr] += rating\n",
    "                \n",
    "                prev = curr\n",
    "            \n",
    "        for startnode in cumulative_ratings.keys():\n",
    "            for nextnode in cumulative_ratings[startnode].keys():\n",
    "                self.graph_edge_weights[startnode][nextnode] *= (1- self.decay)\n",
    "                self.graph_edge_weights[startnode][nextnode] += (cumulative_ratings[startnode][nextnode] / (5* self.trail_max_len))\n",
    "                \n",
    "        del cumulative_ratings\n",
    "    \n",
    "\n",
    "    def compute_best_rec (self,exclude_list):\n",
    "        temp_list = []\n",
    "        self.ants.prep_for_test()\n",
    "        while (len(temp_list)< self.trail_max_len):\n",
    "            test_ant = Ant([])\n",
    "            nextid = self.ants.determine_next_movie(test_ant,self.graph_edge_weights [test_ant.get_current()])\n",
    "            test_ant.watch_movie(nextid)\n",
    "            if (nextid not in exclude_list):\n",
    "                temp_list.append(nextid)\n",
    "        test_ant.clear()\n",
    "        print(len(test_ant.trail))\n",
    "        del test_ant\n",
    "        \n",
    "        return temp_list\n",
    "    \n",
    "    def best_recomendations (self):\n",
    "        return self.best_recommendations\n",
    "    \n",
    "    def one_iter (self): \n",
    "#         print(\"running one iteration: \\n -------------------------------\")\n",
    "        #print(f\" trail max len : {self.trail_max_len}\")\n",
    "        self.ants.clear()\n",
    "        for step in range(0,self.trail_max_len):\n",
    "            #print(\"test\")\n",
    "            self.ants.move_all_ants(self.graph_edge_weights)\n",
    "            \n",
    "        self.update_edge_weights()\n",
    "        self.ants.clear()\n",
    "        \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a3c0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "file = open(\"genresList.pkl\",'rb')\n",
    "genres = load(file)\n",
    "file.close()\n",
    "\n",
    "def create_genre_tracker ():\n",
    "    gt = {}\n",
    "    for g in genres:\n",
    "        gt[g] = 0 \n",
    "    return gt\n",
    "\n",
    "\n",
    "sim_df =  pd.read_csv(\"./simillarity_matrix.csv\")\n",
    "all_vals = []\n",
    "\n",
    "for index, row in sim_df.iterrows():\n",
    "    sim_list = ast.literal_eval(row[\"simillarity_vector\"])\n",
    "    all_vals += sim_list\n",
    "\n",
    "max_sim = max(all_vals)\n",
    "min_Sim = min(all_vals)\n",
    "\n",
    "def z_normalization (val):\n",
    "    return (val-min_Sim)/(max_sim - min_Sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8580bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_simillarity_ratings (l1,l2,movies):\n",
    "    l1_dict = dict(l1)\n",
    "    l2_dict = dict(l2)\n",
    "    simillarity = 0 \n",
    "    \n",
    "    genre_tracker1 = create_genre_tracker ()\n",
    "    genre_tracker2 = create_genre_tracker ()\n",
    "    \n",
    "    l2_keys = list(l2_dict.keys())\n",
    "    for key in l1_dict.keys():\n",
    "        m1_genres = movies.loc[movies['movieId'] == key  ,'genres'].values[0].split(\"|\")\n",
    "        for mg in m1_genres:\n",
    "            genre_tracker1 [mg] +=1\n",
    "        if key in l2_keys:\n",
    "            r1 = l1_dict [key]\n",
    "            r2 = l2_dict [key]\n",
    "            if (r1 < r2):\n",
    "                simillarity += 100*(r1/r2)\n",
    "            else:\n",
    "                simillarity+= 100*(r2/r1) \n",
    "                \n",
    "    for key in l2_keys:\n",
    "        try: \n",
    "            m2_genres = movies.loc[movies['movieId'] == key  ,'genres'].values[0].split(\"|\")\n",
    "            for mg in m2_genres:\n",
    "                genre_tracker2 [mg] +=1\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    genre_simillarity =  0 \n",
    "    for g in genres:\n",
    "        tempg1 = genre_tracker1 [g]\n",
    "        tempg2 = genre_tracker2 [g]\n",
    "        if (tempg1 > 0 or tempg2 >0):\n",
    "            genre_simillarity += (1000* (min(tempg1,tempg2)/max(tempg1,tempg2))* min (tempg1,tempg2))\n",
    "        \n",
    "    return z_normalization(genre_simillarity + simillarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4586604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_simillarity_vector (ratings_df, userlist,movies,exclude_users):\n",
    "    simillarity_dict = {}\n",
    "    \n",
    "    for index, row in ratings_df.iterrows():\n",
    "        user2list = ast.literal_eval (row[\"ratings_list\"])\n",
    "        simillarity_dict [row[\"userId\"]] = compute_simillarity_ratings (userlist,user2list,movies)\n",
    "        \n",
    "    for u in exclude_users:\n",
    "        if (u in simillarity_dict.keys()):\n",
    "            del simillarity_dict[u]\n",
    "        \n",
    "    return [(k,v) for k ,v in simillarity_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a097b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_similar_users(num_agents,user_ratings,exclude_users, userlist,movies, randomize = False):\n",
    "    if ( not randomize):\n",
    "        sim_vec = compute_simillarity_vector (user_ratings, userlist,movies,exclude_users) \n",
    "    \n",
    "            \n",
    "        sim_vec.sort(key=lambda pair: pair[1])\n",
    "        return [a[0] for a in sim_vec[-num_agents:]]\n",
    "    else: \n",
    "        userids = list (range(1,len(user_ratings.index)))\n",
    "        return random.sample(userids, num_agents);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be8e7640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main (num_agents, num_iter, num_movies,exclude_users =[], userlist = [],rating_fn = \"./generation_saves/ratings_gen_50.csv\", simillarility_fn = \"./simillarity_matrix_normalized.csv\", alpha= 0.7,beta =0.3,decay=0.05):\n",
    "    # import datasets\n",
    "    print (\"importing datasets....\")\n",
    "    sim_df  = pd.read_csv(simillarility_fn)\n",
    "    movies  = pd.read_csv(f\"./ml-latest-small/movies.csv\")\n",
    "    user_ratings = pd.read_csv(rating_fn)\n",
    "    \n",
    "    ## if userlist is empty pick 50 random users as agents\n",
    "    rand = (len(userlist) == 0)\n",
    "        \n",
    "    ## if not empty userlist will be the most simillar users \n",
    "    print(f\"selecting {num_agents} simillar users...\")\n",
    "    users = select_similar_users(num_agents, user_ratings,exclude_users, userlist,movies, randomize = rand)\n",
    "    \n",
    "    ## determining all the movies that these users watched\n",
    "    print(\"configuring movie formatting...\")\n",
    "    movie_list = []\n",
    "    tasks = []\n",
    "    for uID in users:\n",
    "        film_list = ast.literal_eval(user_ratings.loc[user_ratings['userId'] == uID][\"ratings_list\"].tolist()[0])\n",
    "        for film,rating in film_list:\n",
    "            if (film not in movie_list):\n",
    "                movie_list.append(film)\n",
    "                tasks.append(Task(film,movies.loc[movies['movieId'] == film]))\n",
    "    \n",
    "    ## define the graph\n",
    "    print(\"creating the Graph...\")\n",
    "    graph = Ant_Graph(movie_list,tasks, num_agents ,num_movies, users, filename = rating_fn , alpha=alpha , beta= beta, decay = decay)\n",
    "    print(f\"Staring training fo {num_iter} iterations...\")\n",
    "    for i in tqdm(range (0,num_iter)):\n",
    "        graph.one_iter()\n",
    "        \n",
    "    movies_user_already_watched = [mid for mid,rate in userlist ]\n",
    "    recs = graph.compute_best_rec (movies_user_already_watched)\n",
    "    print(f\"Recommended ID's: {recs}\")\n",
    "    \n",
    "    \n",
    "    ## Adding some cleanup code to clear all vars because for some reason every second call to main was failing \n",
    "    graph.clear()\n",
    "    del graph, movie_list, tasks, rand, users, user_ratings,sim_df,movies\n",
    "    gc.collect()\n",
    "    \n",
    "    return recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db822e7",
   "metadata": {},
   "source": [
    "## Training and testing \n",
    "\n",
    "### training \n",
    "\n",
    "Training is rather trivial, all weneed to do is make an appropriate call to main()\n",
    "\n",
    "### testing\n",
    "\n",
    "Testing is a bit more difficult. We do not have a list of people who have volunteered to test the system by watching the recomendations and rating them so we have to get creative. We can set a few users in our existing dataset as \"test users\" then we will take the first k ratings of the user as input/\"user history\" and the n-k as \"test ratings\" . We will determine how good the recomendations are using the percentage of the reccomendations that appear in the \"test ratings list and by comparing the ratings for movies that are in both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dad2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metric\n",
    "def evaluate_reccomendations (recs, test_set):\n",
    "    missing_recs =0 \n",
    "    ratings = []\n",
    "    for movieID in recs: \n",
    "        rating = next((y for x, y in test_set if x == movieID ), None)\n",
    "        if (rating == None):\n",
    "            missing_recs+=1\n",
    "        else: \n",
    "            ratings.append(rating)\n",
    "            \n",
    "    percent_overlap = (len(recs) - missing_recs) / len(recs)\n",
    "    \n",
    "    rating_accuracy = 0.5\n",
    "    if (len(ratings) > 0):\n",
    "        rating_accuracy = sum(ratings) / (5*len(ratings))\n",
    "    \n",
    "    return percent_overlap, rating_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd2c34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get 50 test users \n",
    "user_ratings = pd.read_csv(\"./ratings_organized.csv\")\n",
    "chosen_users = random.sample (list(range (0, len(user_ratings.index))),50)  ## we will pass this to main to make sure our train data does not include it \n",
    "\n",
    "train_revs, test_revs = [], []\n",
    "for i in chosen_users:\n",
    "    user_rev  = ast.literal_eval(user_ratings.iloc[[i]] [\"ratings_list\"].tolist()[0])\n",
    "    split_index = int (len(user_rev) * 0.5)\n",
    "    train_revs.append(user_rev[:split_index])\n",
    "    test_revs.append(user_rev[split_index:])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305015fd",
   "metadata": {},
   "source": [
    "# Testing now with different Configs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da543d",
   "metadata": {},
   "source": [
    "## test different generation to observe impact of Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529b513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running training and testing for user 0\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n"
     ]
    }
   ],
   "source": [
    "## no Genetic algorithm evolution\n",
    "ra_list = []\n",
    "for i,rev_list in enumerate(train_revs):\n",
    "    print(f\"running training and testing for user {i}\\n --------------------------------------------\")\n",
    "    recs = main (num_agents =30 , num_iter = 30, num_movies = 5 ,exclude_users = chosen_users , userlist = rev_list ,rating_fn = \"./ratings_organized.csv\", simillarility_fn = \"./simillarity_matrix_normalized.csv\", alpha= 0.7,beta =0.3,decay=0.05)\n",
    "    precent_overlap, ra = evaluate_reccomendations(recs,test_revs[i])\n",
    "    if (precent_overlap != 0 ):\n",
    "        ra_list.append(ra)\n",
    "        \n",
    "print (f\"overall accuracy is {sum(ra_list)/len(ra_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f154f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 50 generations of GA\n",
    "ra_list = []\n",
    "for i,rev_list in enumerate(train_revs):\n",
    "    print(f\"running training and testing for user {i}\\n --------------------------------------------\")\n",
    "    recs = main (num_agents =30 , num_iter = 30, num_movies = 5 ,exclude_users = chosen_users , userlist = rev_list ,rating_fn = \"./generation_saves/ratings_gen_50.csv\", simillarility_fn = \"./simillarity_matrix_normalized.csv\", alpha= 0.7,beta =0.3,decay=0.05)\n",
    "    precent_overlap, ra = evaluate_reccomendations(recs,test_revs[i])\n",
    "    if (precent_overlap != 0 ):\n",
    "        ra_list.append(ra)\n",
    "        \n",
    "print (f\"overall accuracy is {sum(ra_list)/len(ra_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 100 generations of GA\n",
    "ra_list = []\n",
    "for i,rev_list in enumerate(train_revs):\n",
    "    print(f\"running training and testing for user {i}\\n --------------------------------------------\")\n",
    "    recs = main (num_agents =30 , num_iter = 30, num_movies = 5 ,exclude_users = chosen_users , userlist = rev_list ,rating_fn = \"./generation_saves/ratings_gen_100.csv\", simillarility_fn = \"./simillarity_matrix_normalized.csv\", alpha= 0.7,beta =0.3,decay=0.05)\n",
    "    precent_overlap, ra = evaluate_reccomendations(recs,test_revs[i])\n",
    "    if (precent_overlap != 0 ):\n",
    "        ra_list.append(ra)\n",
    "        \n",
    "print (f\"overall accuracy is {sum(ra_list)/len(ra_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 500 generations of GA\n",
    "ra_list = []\n",
    "for i,rev_list in enumerate(train_revs):\n",
    "    print(f\"running training and testing for user {i}\\n --------------------------------------------\")\n",
    "    recs = main (num_agents =30 , num_iter = 30, num_movies = 5 ,exclude_users = chosen_users , userlist = rev_list ,rating_fn = \"./generation_saves/ratings_gen_500.csv\", simillarility_fn = \"./simillarity_matrix_normalized.csv\", alpha= 0.7,beta =0.3,decay=0.05)\n",
    "    precent_overlap, ra = evaluate_reccomendations(recs,test_revs[i])\n",
    "    if (precent_overlap != 0 ):\n",
    "        ra_list.append(ra)\n",
    "        \n",
    "print (f\"overall accuracy is {sum(ra_list)/len(ra_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda7cea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running training and testing for user 0\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [186.0, 3663.0, 9623.0, 912.0, 86644.0]\n",
      "running training and testing for user 1\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1935.0, 6680.0, 6477.0, 1206.0, 2291.0]\n",
      "running training and testing for user 2\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1274.0, 1832.0, 4886.0, 3990.0, 2571.0]\n",
      "running training and testing for user 3\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [583.0, 6184.0, 7364.0, 457.0, 8733.0]\n",
      "running training and testing for user 4\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [593.0, 5694.0, 6818.0, 2394.0, 1372.0]\n",
      "running training and testing for user 5\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 18.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [8695.0, 4692.0, 4273.0, 2640.0, 8964.0]\n",
      "running training and testing for user 6\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1507.0, 7707.0, 1221.0, 9740.0, 4029.0]\n",
      "running training and testing for user 7\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1674.0, 1956.0, 4040.0, 45722.0, 7688.0]\n",
      "running training and testing for user 8\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1078.0, 7662.0, 6456.0, 4428.0, 5233.0]\n",
      "running training and testing for user 9\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [9589.0, 3681.0, 161044.0, 7280.0, 6686.0]\n",
      "running training and testing for user 10\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [107406.0, 94780.0, 6303.0, 7401.0, 3080.0]\n",
      "running training and testing for user 11\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [2866.0, 54259.0, 5859, 2097.0, 230.0]\n",
      "running training and testing for user 12\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [9099.0, 8916.0, 208.0, 8374.0, 719.0]\n",
      "running training and testing for user 13\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [2272.0, 2692.0, 57669.0, 3006.0, 708.0]\n",
      "running training and testing for user 14\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [2081.0, 3806.0, 2000.0, 68954.0, 2950.0]\n",
      "running training and testing for user 15\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [6537.0, 2100.0, 1036.0, 6043.0, 9225.0]\n",
      "running training and testing for user 16\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1950.0, 2467.0, 7804.0, 3353.0, 148626.0]\n",
      "running training and testing for user 17\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [36519.0, 858.0, 69529.0, 3409.0, 474.0]\n",
      "running training and testing for user 18\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1917.0, 1126.0, 6188.0, 1292.0, 9711.0]\n",
      "running training and testing for user 19\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [5757.0, 597.0, 3450.0, 2017.0, 1047.0]\n",
      "running training and testing for user 20\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1921.0, 3936.0, 5973.0, 5617.0, 2722.0]\n",
      "running training and testing for user 21\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [78499.0, 1711.0, 5075.0, 5693.0, 6157.0]\n",
      "running training and testing for user 22\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [49396.0, 8529.0, 8679.0, 6863.0, 3234.0]\n",
      "running training and testing for user 23\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [6754.0, 9610.0, 8318.0, 8161.0, 787.0]\n",
      "running training and testing for user 24\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [2794.0, 6992.0, 2398.0, 4406.0, 143859.0]\n",
      "running training and testing for user 25\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [9604.0, 1478.0, 89087.0, 5128.0, 2294.0]\n",
      "running training and testing for user 26\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [74508.0, 1201.0, 5444.0, 7438.0, 1089.0]\n",
      "running training and testing for user 27\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [923.0, 2599.0, 8669.0, 75805.0, 6763.0]\n",
      "running training and testing for user 28\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [9101.0, 3782.0, 9581.0, 8945.0, 1474.0]\n",
      "running training and testing for user 29\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [3967.0, 7297.0, 94959.0, 2021.0, 5658.0]\n",
      "running training and testing for user 30\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [3606.0, 182823.0, 2030.0, 7748.0, 3395.0]\n",
      "running training and testing for user 31\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [4547.0, 1960.0, 5140.0, 1285.0, 2957.0]\n",
      "running training and testing for user 32\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [485.0, 3856.0, 2012.0, 5276.0, 122.0]\n",
      "running training and testing for user 33\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [139385.0, 2917.0, 2248.0, 2038.0, 1920.0]\n",
      "running training and testing for user 34\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [5946.0, 1050.0, 1214.0, 309.0, 9683.0]\n",
      "running training and testing for user 35\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [750.0, 5878.0, 91529.0, 698.0, 919.0]\n",
      "running training and testing for user 36\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1464.0, 2295.0, 6971.0, 4304.0, 2485.0]\n",
      "running training and testing for user 37\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1030.0, 426.0, 3213.0, 2804.0, 1666.0]\n",
      "running training and testing for user 38\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [4027.0, 8542.0, 6916.0, 44199.0, 6538.0]\n",
      "running training and testing for user 39\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [9096.0, 59784.0, 4336.0, 922.0, 4563.0]\n",
      "running training and testing for user 40\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [7185.0, 1356.0, 377.0, 1278.0, 3371.0]\n",
      "running training and testing for user 41\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [4769.0, 66097.0, 2791.0, 9222.0, 2098.0]\n",
      "running training and testing for user 42\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [1555.0, 1972.0, 1617.0, 3397.0, 1196.0]\n",
      "running training and testing for user 43\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [664.0, 5999.0, 4179.0, 37729.0, 103335.0]\n",
      "running training and testing for user 44\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [30793.0, 2567.0, 4612.0, 1777.0, 39.0]\n",
      "running training and testing for user 45\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [4868.0, 168144.0, 50.0, 6327.0, 5177.0]\n",
      "running training and testing for user 46\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [3526.0, 5329.0, 1082.0, 7231.0, 8992.0]\n",
      "running training and testing for user 47\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [4084.0, 6216.0, 3253.0, 6492.0, 2437.0]\n",
      "running training and testing for user 48\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [5257.0, 7963.0, 11.0, 60069.0, 2204]\n",
      "running training and testing for user 49\n",
      " --------------------------------------------\n",
      "importing datasets....\n",
      "selecting 30 simillar users...\n",
      "configuring movie formatting...\n",
      "creating the Graph...\n",
      "Staring training fo 30 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended ID's: [5065.0, 2411.0, 5155.0, 4855.0, 780.0]\n",
      "overall accuracy is 0.7928571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 1000 generations of GA\n",
    "ra_list = []\n",
    "for i,rev_list in enumerate(train_revs):\n",
    "    print(f\"running training and testing for user {i}\\n --------------------------------------------\")\n",
    "    recs = main (num_agents =30 , num_iter = 30, num_movies = 5 ,exclude_users = chosen_users , userlist = rev_list ,rating_fn = \"./generation_saves/ratings_gen_1000.csv\", simillarility_fn = \"./simillarity_matrix_normalized.csv\", alpha= 0.7,beta =0.3,decay=0.05)\n",
    "    precent_overlap, ra = evaluate_reccomendations(recs,test_revs[i])\n",
    "    if (precent_overlap != 0 ):\n",
    "        ra_list.append(ra)\n",
    "        \n",
    "print (f\"overall accuracy is {sum(ra_list)/len(ra_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e731f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db99881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755a9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
